{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a3ae483",
   "metadata": {},
   "source": [
    "# A1_4 â€“ Regularisation\n",
    "\n",
    "In this notebook we compare different regularisation techniques applied to our neturalnet_torch model.\n",
    "\n",
    "More specifically, we compare:\n",
    "\n",
    "- L1/L2 Regularisation\n",
    "- Dropout Regularisation\n",
    "\n",
    "For each:\n",
    "\n",
    "- We experiment with different parameters\n",
    "- We present the results of the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bb9b149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "import joblib\n",
    "\n",
    "base = os.path.dirname(os.getcwd())  \n",
    "sys.path.append(os.path.join(base, \"models\"))\n",
    "sys.path.append(os.path.join(base, \"utils\"))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from utils import predict_batch, mape, evaluate_regression\n",
    "from NeuralNet import NeuralNet                      # manual BP implementation\n",
    "from mlr_sklearn import MultipleLinearRegressionSK   # simple MLR wrapper\n",
    "from neuralnet_torch import NeuralNetTorch           # PyTorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "965e3aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded preprocessed data from ../data\n",
      "X_trainval_np: (1200, 61)\n",
      "X_test_np    : (300, 61)\n",
      "n_features   : 61\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data from ./data\n",
    "X_trainval_np = np.load(\"../data/X_trainval_np.npy\")\n",
    "X_test_np     = np.load(\"../data/X_test_np.npy\")\n",
    "\n",
    "y_trainval = np.load(\"../data/y_trainval.npy\")\n",
    "y_test     = np.load(\"../data/y_test.npy\")\n",
    "\n",
    "y_trainval_scaled = np.load(\"../data/y_trainval_scaled.npy\")\n",
    "y_test_scaled     = np.load(\"../data/y_test_scaled.npy\")\n",
    "\n",
    "x_scaler = joblib.load(\"../data/x_scaler.joblib\")\n",
    "y_scaler = joblib.load(\"../data/y_scaler.joblib\")\n",
    "\n",
    "n_features = X_trainval_np.shape[1]\n",
    "print(\"Loaded preprocessed data from ../data\")\n",
    "print(\"X_trainval_np:\", X_trainval_np.shape)\n",
    "print(\"X_test_np    :\", X_test_np.shape)\n",
    "print(\"n_features   :\", n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "134da496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual BP selected configuration:\n",
      "Hidden layers : [40, 15]\n",
      "Epochs        : 600\n",
      "Learning rate : 0.005\n",
      "Momentum      : 0.9\n",
      "Activation    : tanh\n"
     ]
    }
   ],
   "source": [
    "# Selected configuration for manual BP, we copy here the desired Hyperpaarameters from the notebook 2\n",
    "\n",
    "hidden_layers_bp = [40, 15]\n",
    "epochs_bp = 600\n",
    "lr_bp = 0.005\n",
    "momentum_bp = 0.9\n",
    "activation_bp = \"tanh\"\n",
    "\n",
    "print(\"Manual BP selected configuration:\")\n",
    "print(\"Hidden layers :\", hidden_layers_bp)\n",
    "print(\"Epochs        :\", epochs_bp)\n",
    "print(\"Learning rate :\", lr_bp)\n",
    "print(\"Momentum      :\", momentum_bp)\n",
    "print(\"Activation    :\", activation_bp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15fa0779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetTorch (PyTorch) initialized\n",
      " - Layers: [61, 40, 15, 1]\n",
      " - Activation: tanh\n",
      " - Learning rate: 0.005 | Momentum: 0.9\n",
      " - Epochs: 600 | Val split: 0.2\n",
      "\n",
      "Testing regularisation: None\n",
      "Epoch 0: Train MSE=1.050383 | Val MSE=1.119804\n",
      "Epoch 100: Train MSE=0.090887 | Val MSE=0.111286\n",
      "Epoch 200: Train MSE=0.076372 | Val MSE=0.099934\n",
      "Epoch 300: Train MSE=0.066288 | Val MSE=0.092341\n",
      "Epoch 400: Train MSE=0.057634 | Val MSE=0.086009\n",
      "Epoch 500: Train MSE=0.049924 | Val MSE=0.080445\n",
      "=== PyTorch Neural Network (same config) ===\n",
      "TRAIN+VAL: {'MSE': 0.07876244510237074, 'MAE': 0.1944299341935785, 'MAPE': 6.85705512755216}\n",
      "TEST     : {'MSE': 0.12720147620255262, 'MAE': 0.22979684749645599, 'MAPE': 9.380183141727464}\n",
      "\n",
      "Testing regularisation: L1\n",
      "Epoch 0: Train MSE=0.050986 | Val MSE=0.052019\n",
      "Epoch 100: Train MSE=0.043431 | Val MSE=0.051435\n",
      "Epoch 200: Train MSE=0.037204 | Val MSE=0.047063\n",
      "Epoch 300: Train MSE=0.031407 | Val MSE=0.043041\n",
      "Epoch 400: Train MSE=0.026244 | Val MSE=0.039745\n",
      "Epoch 500: Train MSE=0.022084 | Val MSE=0.037520\n",
      "=== PyTorch Neural Network (same config) ===\n",
      "TRAIN+VAL: {'MSE': 0.07876244510237074, 'MAE': 0.1944299341935785, 'MAPE': 6.85705512755216}\n",
      "TEST     : {'MSE': 0.12720147620255262, 'MAE': 0.22979684749645599, 'MAPE': 9.380183141727464}\n",
      "\n",
      "Testing regularisation: L2\n",
      "Epoch 0: Train MSE=0.020437 | Val MSE=0.022739\n",
      "Epoch 100: Train MSE=0.016903 | Val MSE=0.025142\n",
      "Epoch 200: Train MSE=0.014829 | Val MSE=0.025878\n",
      "Epoch 300: Train MSE=0.013252 | Val MSE=0.026582\n",
      "Epoch 400: Train MSE=0.011974 | Val MSE=0.027244\n",
      "Epoch 500: Train MSE=0.010903 | Val MSE=0.027873\n",
      "=== PyTorch Neural Network (same config) ===\n",
      "TRAIN+VAL: {'MSE': 0.07876244510237074, 'MAE': 0.1944299341935785, 'MAPE': 6.85705512755216}\n",
      "TEST     : {'MSE': 0.12720147620255262, 'MAE': 0.22979684749645599, 'MAPE': 9.380183141727464}\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Neural Network \n",
    "\n",
    "hidden_layers_torch = hidden_layers_bp\n",
    "layers_torch = [n_features] + hidden_layers_torch + [1]\n",
    "\n",
    "net_torch = NeuralNetTorch(\n",
    "    n=layers_torch,\n",
    "    fact=activation_bp,   # same activation\n",
    "    eta=lr_bp,            # same learning rate\n",
    "    alpha=momentum_bp,    # same momentum\n",
    "    epochs=epochs_bp,     # same number of epochs\n",
    "    val_split=0.2         # same validation split\n",
    ")\n",
    "\n",
    "regularisation = ['None', 'L1', 'L2']\n",
    "results = []   \n",
    "\n",
    "for reg in regularisation:\n",
    "    print(\"\\nTesting regularisation:\", reg)\n",
    "    \n",
    "    # Train with scaled data\n",
    "    net_torch.fit(X_trainval_np, y_trainval_scaled, reg)\n",
    "\n",
    "    # Loss history for later plots\n",
    "    train_err_torch, val_err_torch = net_torch.loss_epochs()\n",
    "    \n",
    "    # Predictions in scaled space\n",
    "    y_trainval_pred_torch_scaled = net_torch.predict(X_trainval_np).reshape(-1, 1)\n",
    "    y_test_pred_torch_scaled     = net_torch.predict(X_test_np).reshape(-1, 1)\n",
    "    \n",
    "    # Back to original target scale (cnt_log)\n",
    "    y_trainval_pred_torch = y_scaler.inverse_transform(y_trainval_pred_torch_scaled).ravel()\n",
    "    y_test_pred_torch     = y_scaler.inverse_transform(y_test_pred_torch_scaled).ravel()\n",
    "    \n",
    "    # Metrics (in original cnt_log scale)\n",
    "    metrics_trainval = evaluate_regression(y_trainval, y_trainval_pred_torch)\n",
    "    metrics_test     = evaluate_regression(y_test,     y_test_pred_torch)\n",
    "\n",
    "    print(\"=== PyTorch Neural Network (same config) ===\")\n",
    "    print(\"TRAIN+VAL:\", metrics_torch_trainval)\n",
    "    print(\"TEST     :\", metrics_torch_test)\n",
    "\n",
    "    # Store results\n",
    "    # Add TRAIN+VAL row\n",
    "    results.append({\n",
    "        \"Regularisation\": reg,\n",
    "        \"Split\": \"Train+Val\",\n",
    "        \"MSE\":  metrics_trainval[\"MSE\"],\n",
    "        \"MAE\":  metrics_trainval[\"MAE\"],\n",
    "        \"MAPE\": metrics_trainval[\"MAPE\"],\n",
    "    })\n",
    "\n",
    "    # Add TEST row\n",
    "    results.append({\n",
    "        \"Regularisation\": reg,\n",
    "        \"Split\": \"Test\",\n",
    "        \"MSE\":  metrics_test[\"MSE\"],\n",
    "        \"MAE\":  metrics_test[\"MAE\"],\n",
    "        \"MAPE\": metrics_test[\"MAPE\"],\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7f6da15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training metrics w/ Regularisation ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regularisation</th>\n",
       "      <th>Split</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Train+Val</td>\n",
       "      <td>0.097742</td>\n",
       "      <td>0.197781</td>\n",
       "      <td>7.445139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.138763</td>\n",
       "      <td>0.228323</td>\n",
       "      <td>9.770781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L1</td>\n",
       "      <td>Train+Val</td>\n",
       "      <td>0.040916</td>\n",
       "      <td>0.128934</td>\n",
       "      <td>4.827589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L1</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.082052</td>\n",
       "      <td>0.169946</td>\n",
       "      <td>7.757051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L2</td>\n",
       "      <td>Train+Val</td>\n",
       "      <td>0.026633</td>\n",
       "      <td>0.101997</td>\n",
       "      <td>3.738414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L2</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.073022</td>\n",
       "      <td>0.152818</td>\n",
       "      <td>7.291093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Regularisation      Split       MSE       MAE      MAPE\n",
       "0           None  Train+Val  0.097742  0.197781  7.445139\n",
       "1           None       Test  0.138763  0.228323  9.770781\n",
       "2             L1  Train+Val  0.040916  0.128934  4.827589\n",
       "3             L1       Test  0.082052  0.169946  7.757051\n",
       "4             L2  Train+Val  0.026633  0.101997  3.738414\n",
       "5             L2       Test  0.073022  0.152818  7.291093"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Comparison tables: TRAIN+VAL and TEST metrics\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "print(\"=== Training metrics w/ Regularisation ===\")\n",
    "display(df_results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7982c429",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_err_manual' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Loss curves for manual BP and PyTorch\u001b[39;00m\n\u001b[32m      3\u001b[39m plt.figure()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m plt.plot(\u001b[43mtrain_err_manual\u001b[49m, label=\u001b[33m\"\u001b[39m\u001b[33mManual BP - Train MSE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(e \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m val_err_manual):\n\u001b[32m      6\u001b[39m     plt.plot([e \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m val_err_manual \u001b[38;5;28;01mif\u001b[39;00m e \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m], label=\u001b[33m\"\u001b[39m\u001b[33mManual BP - Val MSE\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_err_manual' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Loss curves for manual BP and PyTorch\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_err_manual, label=\"Manual BP - Train MSE\")\n",
    "if any(e is not None for e in val_err_manual):\n",
    "    plt.plot([e for e in val_err_manual if e is not None], label=\"Manual BP - Val MSE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"Manual NeuralNet - Loss per epoch\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_err_torch, label=\"PyTorch NN - Train MSE\")\n",
    "if any(e is not None for e in val_err_torch):\n",
    "    plt.plot([e for e in val_err_torch if e is not None], label=\"PyTorch NN - Val MSE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"PyTorch NeuralNet - Loss per epoch\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8bea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scatter plots: true vs predicted on TEST set\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "# Manual BP\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(y_test, y_test_pred_manual, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()],\n",
    "         [y_test.min(), y_test.max()],\n",
    "         linestyle=\"--\")\n",
    "plt.xlabel(\"True cnt_log (test)\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Manual BP\")\n",
    "\n",
    "# MLR\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(y_test, y_test_pred_mlr, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()],\n",
    "         [y_test.min(), y_test.max()],\n",
    "         linestyle=\"--\")\n",
    "plt.xlabel(\"True cnt_log (test)\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"MLR (scikit-learn)\")\n",
    "\n",
    "# PyTorch NN\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(y_test, y_test_pred_torch, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()],\n",
    "         [y_test.min(), y_test.max()],\n",
    "         linestyle=\"--\")\n",
    "plt.xlabel(\"True cnt_log (test)\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"PyTorch NN\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ffa2a3",
   "metadata": {},
   "source": [
    "## Summary of model comparison\n",
    "\n",
    "In this notebook we compared three regression models on the same\n",
    "Bike Sharing hourly dataset:\n",
    "\n",
    "- **Manual BP Neural Network** (custom implementation),\n",
    "- **Multiple Linear Regression (MLR)** using scikit-learn,\n",
    "- **PyTorch Neural Network** using the same architecture and hyperparameters as the manual BP model.\n",
    "\n",
    "The main points are:\n",
    "\n",
    "- All models were trained on the same **scaled** features and target.\n",
    "- The manual BP and the PyTorch models used the same:\n",
    "  - number of layers and neurons,\n",
    "  - activation function,\n",
    "  - learning rate, momentum,\n",
    "  - number of epochs,\n",
    "  - internal validation split.\n",
    "- We measured performance using **MSE, MAE and MAPE** on:\n",
    "  - the 80% train+validation set,\n",
    "  - the 20% test set.\n",
    "\n",
    "From the comparison tables and plots we can discuss:\n",
    "\n",
    "- How the linear model (MLR) behaves compared to the nonlinear neural networks.\n",
    "- Whether PyTorch reproduces or improves the performance of the manual BP implementation.\n",
    "- How stable each model is during training (by looking at the loss curves).\n",
    "- How close the predictions are to the true values on the test set (scatter plots).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0476b6-1da8-4a9e-a93c-ee9a4d03ce5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
