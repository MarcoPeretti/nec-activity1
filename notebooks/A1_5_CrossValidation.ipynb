{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f8c816f",
   "metadata": {},
   "source": [
    "# A1_5 â€“ Optional Part 2: Cross Validattion\n",
    "\n",
    "We are using the BP from scratch model + KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75b4d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and classes\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import joblib\n",
    "import sys , os\n",
    "base = os.path.dirname(os.getcwd())  \n",
    "sys.path.append(os.path.join(base, \"models\"))\n",
    "sys.path.append(os.path.join(base, \"utils\"))\n",
    "from NeuralNet import NeuralNet\n",
    "from utils import predict_batch, mape, evaluate_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34357710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trainval_np: (1200, 61)\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data from ../data\n",
    "X_trainval_np = np.load(\"../data/X_trainval_np.npy\")\n",
    "y_trainval = np.load(\"../data/y_trainval.npy\")\n",
    "y_trainval_scaled = np.load(\"../data/y_trainval_scaled.npy\")\n",
    "y_scaler = joblib.load(\"../data/y_scaler.joblib\")\n",
    "\n",
    "n_features = X_trainval_np.shape[1]\n",
    "print(\"X_trainval_np:\", X_trainval_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be5b6ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration to evaluate with K-Fold\n",
    "\n",
    "# Set hyperparameters for the evaluations\n",
    "cv_configs = [\n",
    "    {\n",
    "        \"name\": \"One Layer tanh\",\n",
    "        \"hidden_layers\": [20],\n",
    "        \"epochs\": 400,\n",
    "        \"lr\": 0.005,\n",
    "        \"momentum\": 0.5,\n",
    "        \"activation\": \"tanh\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Deep tanh\",\n",
    "        \"hidden_layers\": [40, 15],\n",
    "        \"epochs\": 600,\n",
    "        \"lr\": 0.005,\n",
    "        \"momentum\": 0.9,\n",
    "        \"activation\": \"tanh\",\n",
    "    },\n",
    "]\n",
    "\n",
    "k_folds = 5\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32582f30",
   "metadata": {},
   "source": [
    "### K-fold cross-validation for hyperparameter evaluation\n",
    "\n",
    "In this section we use **k-fold cross-validation** to evaluate different neural network configurations.\n",
    "\n",
    "The idea is the following:\n",
    "\n",
    "- We have a list of model configurations (`cv_configs`), with different\n",
    "  hyperparameters (number of layers, learning rate, momentum, activation, etc.).\n",
    "- For each configuration, we use **KFold** to split the training+validation data\n",
    "  into `k_folds` parts.\n",
    "- In every fold, we train the network on `k-1` parts and validate it on the\n",
    "  remaining part.\n",
    "- We repeat this process for all folds, so every sample is used for validation once.\n",
    "\n",
    "For each fold we compute three regression metrics:\n",
    "\n",
    "- **MSE** (Mean Squared Error)  \n",
    "- **MAE** (Mean Absolute Error)  \n",
    "- **MAPE** (Mean Absolute Percentage Error)\n",
    "\n",
    "At the end, we calculate the **mean** and **standard deviation** of these metrics across all folds, for each configuration.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2696120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================\n",
      "Config: One Layer tanh\n",
      "====================================\n",
      "Fold 1/5\n",
      "Neural network has been initialized\n",
      "Architecture (neurons per layer): [61, 20, 1]\n",
      "Activation function used: tanh\n",
      " Layer 1: w(20, 61), theta(20, 1)\n",
      " Layer 2: w(1, 20), theta(1, 1)\n",
      "Epoch 0: Train MSE=0.130934\n",
      "Epoch 100: Train MSE=0.002844\n",
      "Epoch 200: Train MSE=0.001117\n",
      "Epoch 300: Train MSE=0.000650\n",
      "Fold 2/5\n",
      "Neural network has been initialized\n",
      "Architecture (neurons per layer): [61, 20, 1]\n",
      "Activation function used: tanh\n",
      " Layer 1: w(20, 61), theta(20, 1)\n",
      " Layer 2: w(1, 20), theta(1, 1)\n",
      "Epoch 0: Train MSE=0.110835\n",
      "Epoch 100: Train MSE=0.003374\n",
      "Epoch 200: Train MSE=0.001460\n",
      "Epoch 300: Train MSE=0.000815\n",
      "Fold 3/5\n",
      "Neural network has been initialized\n",
      "Architecture (neurons per layer): [61, 20, 1]\n",
      "Activation function used: tanh\n",
      " Layer 1: w(20, 61), theta(20, 1)\n",
      " Layer 2: w(1, 20), theta(1, 1)\n",
      "Epoch 0: Train MSE=0.114296\n",
      "Epoch 100: Train MSE=0.003571\n",
      "Epoch 200: Train MSE=0.001298\n",
      "Epoch 300: Train MSE=0.000669\n",
      "Fold 4/5\n",
      "Neural network has been initialized\n",
      "Architecture (neurons per layer): [61, 20, 1]\n",
      "Activation function used: tanh\n",
      " Layer 1: w(20, 61), theta(20, 1)\n",
      " Layer 2: w(1, 20), theta(1, 1)\n",
      "Epoch 0: Train MSE=0.114826\n",
      "Epoch 100: Train MSE=0.003238\n",
      "Epoch 200: Train MSE=0.001355\n",
      "Epoch 300: Train MSE=0.000589\n",
      "Fold 5/5\n",
      "Neural network has been initialized\n",
      "Architecture (neurons per layer): [61, 20, 1]\n",
      "Activation function used: tanh\n",
      " Layer 1: w(20, 61), theta(20, 1)\n",
      " Layer 2: w(1, 20), theta(1, 1)\n",
      "Epoch 0: Train MSE=0.118476\n",
      "Epoch 100: Train MSE=0.003937\n",
      "Epoch 200: Train MSE=0.001380\n",
      "Epoch 300: Train MSE=0.000682\n",
      "\n",
      "====================================\n",
      "Config: Deep tanh\n",
      "====================================\n",
      "Fold 1/5\n",
      "Neural network has been initialized\n",
      "Architecture (neurons per layer): [61, 40, 15, 1]\n",
      "Activation function used: tanh\n",
      " Layer 1: w(40, 61), theta(40, 1)\n",
      " Layer 2: w(15, 40), theta(15, 1)\n",
      " Layer 3: w(1, 15), theta(1, 1)\n",
      "Epoch 0: Train MSE=0.109537\n",
      "Epoch 100: Train MSE=0.000325\n",
      "Epoch 200: Train MSE=0.000165\n",
      "Epoch 300: Train MSE=0.000089\n",
      "Epoch 400: Train MSE=0.000065\n",
      "Epoch 500: Train MSE=0.000053\n",
      "Fold 2/5\n",
      "Neural network has been initialized\n",
      "Architecture (neurons per layer): [61, 40, 15, 1]\n",
      "Activation function used: tanh\n",
      " Layer 1: w(40, 61), theta(40, 1)\n",
      " Layer 2: w(15, 40), theta(15, 1)\n",
      " Layer 3: w(1, 15), theta(1, 1)\n",
      "Epoch 0: Train MSE=0.096694\n",
      "Epoch 100: Train MSE=0.000241\n",
      "Epoch 200: Train MSE=0.000080\n",
      "Epoch 300: Train MSE=0.000059\n",
      "Epoch 400: Train MSE=0.000051\n",
      "Epoch 500: Train MSE=0.000044\n",
      "Fold 3/5\n",
      "Neural network has been initialized\n",
      "Architecture (neurons per layer): [61, 40, 15, 1]\n",
      "Activation function used: tanh\n",
      " Layer 1: w(40, 61), theta(40, 1)\n",
      " Layer 2: w(15, 40), theta(15, 1)\n",
      " Layer 3: w(1, 15), theta(1, 1)\n",
      "Epoch 0: Train MSE=0.112006\n",
      "Epoch 100: Train MSE=0.000343\n",
      "Epoch 200: Train MSE=0.000083\n",
      "Epoch 300: Train MSE=0.000030\n",
      "Epoch 400: Train MSE=0.000018\n",
      "Epoch 500: Train MSE=0.000011\n",
      "Fold 4/5\n",
      "Neural network has been initialized\n",
      "Architecture (neurons per layer): [61, 40, 15, 1]\n",
      "Activation function used: tanh\n",
      " Layer 1: w(40, 61), theta(40, 1)\n",
      " Layer 2: w(15, 40), theta(15, 1)\n",
      " Layer 3: w(1, 15), theta(1, 1)\n",
      "Epoch 0: Train MSE=0.110284\n",
      "Epoch 100: Train MSE=0.000229\n",
      "Epoch 200: Train MSE=0.000084\n",
      "Epoch 300: Train MSE=0.000033\n",
      "Epoch 400: Train MSE=0.000015\n",
      "Epoch 500: Train MSE=0.000024\n",
      "Fold 5/5\n",
      "Neural network has been initialized\n",
      "Architecture (neurons per layer): [61, 40, 15, 1]\n",
      "Activation function used: tanh\n",
      " Layer 1: w(40, 61), theta(40, 1)\n",
      " Layer 2: w(15, 40), theta(15, 1)\n",
      " Layer 3: w(1, 15), theta(1, 1)\n",
      "Epoch 0: Train MSE=0.104073\n",
      "Epoch 100: Train MSE=0.000360\n",
      "Epoch 200: Train MSE=0.000078\n",
      "Epoch 300: Train MSE=0.000158\n",
      "Epoch 400: Train MSE=0.000047\n",
      "Epoch 500: Train MSE=0.000049\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Folds</th>\n",
       "      <th>MSE_mean</th>\n",
       "      <th>MSE_std</th>\n",
       "      <th>MAE_mean</th>\n",
       "      <th>MAE_std</th>\n",
       "      <th>MAPE_mean</th>\n",
       "      <th>MAPE_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One Layer tanh</td>\n",
       "      <td>5</td>\n",
       "      <td>0.144870</td>\n",
       "      <td>0.028006</td>\n",
       "      <td>0.281204</td>\n",
       "      <td>0.027271</td>\n",
       "      <td>8.701866</td>\n",
       "      <td>0.861044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deep tanh</td>\n",
       "      <td>5</td>\n",
       "      <td>0.070644</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>0.142725</td>\n",
       "      <td>0.010650</td>\n",
       "      <td>5.777755</td>\n",
       "      <td>0.362251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name  Folds  MSE_mean   MSE_std  MAE_mean   MAE_std  MAPE_mean  \\\n",
       "0  One Layer tanh      5  0.144870  0.028006  0.281204  0.027271   8.701866   \n",
       "1       Deep tanh      5  0.070644  0.008828  0.142725  0.010650   5.777755   \n",
       "\n",
       "   MAPE_std  \n",
       "0  0.861044  \n",
       "1  0.362251  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " # Loop of K-Fold for each configuration\n",
    "\n",
    "# This list will store the average metrics for each model configuration\n",
    "cv_results = []\n",
    "\n",
    "# Loop over every configuration defined in cv_configs\n",
    "for cfg in cv_configs:\n",
    "    print(\"\\n====================================\")\n",
    "    print(\"Config:\", cfg[\"name\"])\n",
    "    print(\"====================================\")\n",
    "\n",
    "    # Lists to save the metrics of each fold\n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "    mape_list = []\n",
    "\n",
    "    # K-Fold is applied on the training + validation set (80% of the data) kf.split(...) returns the indexes for train and validation in each fold\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_trainval_np), start=1):\n",
    "        print(f\"Fold {fold}/{k_folds}\")\n",
    "\n",
    "        # Select the training and validation features\n",
    "        X_tr = X_trainval_np[train_idx]\n",
    "        X_val = X_trainval_np[val_idx]\n",
    "\n",
    "        # Target for training must stay in scaled form\n",
    "        y_tr_scaled = y_trainval_scaled[train_idx]\n",
    "\n",
    "        # Validation target stays in original scale (\n",
    "        y_val = y_trainval[val_idx]\n",
    "\n",
    "        # Build the network structure: input size -> hidden layers -> 1 output neuron\n",
    "        layers = [n_features] + cfg[\"hidden_layers\"] + [1]\n",
    "\n",
    "        # Create the neural network with the current hyperparameters\n",
    "        net = NeuralNet(\n",
    "            n=layers,                 # network structure\n",
    "            fact=cfg[\"activation\"],   # activation function\n",
    "            eta=cfg[\"lr\"],            # learning rate\n",
    "            alpha=cfg[\"momentum\"],    # momentum value\n",
    "            epochs=cfg[\"epochs\"],     # number of training epochs\n",
    "            val_split=0.0             # no internal validation (we already use K-Fold)\n",
    "        )\n",
    "\n",
    "        # Train the network with the current fold data\n",
    "        net.fit(X_tr, y_tr_scaled)\n",
    "\n",
    "        # Predict on the validation fold (still in scaled form)\n",
    "        y_val_pred_scaled = predict_batch(net, X_val)\n",
    "\n",
    "        # Convert predictions back to the original target scale\n",
    "        y_val_pred = y_scaler.inverse_transform(y_val_pred_scaled).ravel()\n",
    "\n",
    "        # Calculate MSE, MAE and MAPE for this fold\n",
    "        metrics = evaluate_regression(y_val, y_val_pred)\n",
    "\n",
    "        # Save the metrics for this fold\n",
    "        mse_list.append(metrics[\"MSE\"])\n",
    "        mae_list.append(metrics[\"MAE\"])\n",
    "        mape_list.append(metrics[\"MAPE\"])\n",
    "\n",
    "    # After finishing all folds, compute the mean and standard deviation for each metric and save them in the results list\n",
    "    cv_results.append({\n",
    "        \"Name\":      cfg[\"name\"],\n",
    "        \"Folds\":     k_folds,\n",
    "        \"MSE_mean\":  np.mean(mse_list),\n",
    "        \"MSE_std\":   np.std(mse_list),\n",
    "        \"MAE_mean\":  np.mean(mae_list),\n",
    "        \"MAE_std\":   np.std(mae_list),\n",
    "        \"MAPE_mean\": np.mean(mape_list),\n",
    "        \"MAPE_std\":  np.std(mape_list),\n",
    "    })\n",
    "\n",
    "# Create a DataFrame to show the final results in a clean table\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "display(cv_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
