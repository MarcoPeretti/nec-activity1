{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b2cfbc5",
   "metadata": {},
   "source": [
    "# A1 - Comparison of MLR, Manual BP Neural Network and PyTorch Neural Network\n",
    "\n",
    "In this notebook we use the **Bike Sharing (hourly) encoded dataset** and compare\n",
    "three different regression models:\n",
    "\n",
    "- Multiple Linear Regression (MLR) using scikit-learn\n",
    "- A custom neural network implemented from scratch (manual backprop)\n",
    "- A neural network implemented with PyTorch\n",
    "\n",
    "We use the same dataset, the same train/test split and the same scaling for all models.\n",
    "\n",
    "The regression target is **cnt_log**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdebc27e",
   "metadata": {},
   "source": [
    "# Imports and Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0abddf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape (features): (1500, 61)\n",
      "Target shape: (1500,)\n",
      "Feature columns: ['holiday', 'workingday', 'temp', 'atemp', 'hum', 'windspeed', 'casual', 'registered', 'season_1', 'season_2', 'season_3', 'season_4', 'yr_0', 'yr_1', 'mnth_1', 'mnth_2', 'mnth_3', 'mnth_4', 'mnth_5', 'mnth_6', 'mnth_7', 'mnth_8', 'mnth_9', 'mnth_10', 'mnth_11', 'mnth_12', 'hr_0', 'hr_1', 'hr_2', 'hr_3', 'hr_4', 'hr_5', 'hr_6', 'hr_7', 'hr_8', 'hr_9', 'hr_10', 'hr_11', 'hr_12', 'hr_13', 'hr_14', 'hr_15', 'hr_16', 'hr_17', 'hr_18', 'hr_19', 'hr_20', 'hr_21', 'hr_22', 'hr_23', 'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weathersit_1', 'weathersit_2', 'weathersit_3', 'weathersit_4']\n"
     ]
    }
   ],
   "source": [
    "# A1 - Neural Networks and Regression (Model Comparison)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from models.NeuralNet import NeuralNet                # custom BP implementation (from scratch)\n",
    "from models.mlr_sklearn import MultipleLinearRegressionSK\n",
    "from models.neuralnet_torch import NeuralNetTorch\n",
    "\n",
    "\n",
    "\n",
    "# Load dataset (Bike Sharing - hourly, preprocessed/encoded)\n",
    "hours = pd.read_csv(\"hours_encoded.csv\")\n",
    "\n",
    "# We use cnt_log as the regression target (drop original cnt)\n",
    "hours = hours.drop(columns=[\"cnt\"])\n",
    "\n",
    "# Shuffle and take first 1500 samples, as required\n",
    "hours = hours.sample(n=1500, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Separate features and target\n",
    "X_df = hours.drop(columns=[\"cnt_log\"])\n",
    "y = hours[\"cnt_log\"].values\n",
    "\n",
    "print(\"Data shape (features):\", X_df.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "print(\"Feature columns:\", X_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0c09ef",
   "metadata": {},
   "source": [
    "# Train - Test Split & Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cade427d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train+Val size: 1200\n",
      "Test size     : 300\n",
      "Number of input features: 61\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train / Test split\n",
    "\n",
    "# 80% -> train+validation (trainval)\n",
    "# 20% -> test\n",
    "X_trainval_df, X_test_df, y_trainval, y_test = train_test_split(\n",
    "    X_df, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Train+Val size:\", X_trainval_df.shape[0])\n",
    "print(\"Test size     :\", X_test_df.shape[0])\n",
    "\n",
    "# Convert to NumPy\n",
    "X_trainval = X_trainval_df.values\n",
    "X_test = X_test_df.values\n",
    "\n",
    "# Feature scaling (StandardScaler for X)\n",
    "x_scaler = StandardScaler()\n",
    "X_trainval_np = x_scaler.fit_transform(X_trainval)\n",
    "X_test_np     = x_scaler.transform(X_test)\n",
    "\n",
    "# Target scaling (StandardScaler for y)\n",
    "# We scale cnt_log to help neural networks training.\n",
    "y_scaler = StandardScaler()\n",
    "y_trainval_scaled = y_scaler.fit_transform(y_trainval.reshape(-1, 1)).ravel()\n",
    "y_test_scaled     = y_scaler.transform(y_test.reshape(-1, 1)).ravel()\n",
    "\n",
    "n_features = X_trainval_np.shape[1]\n",
    "print(\"Number of input features:\", n_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce496e6",
   "metadata": {},
   "source": [
    "# Predict_batch & Definition of MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44662e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(model, X):\n",
    "    \"\"\"\n",
    "    Run model.predict on each sample in X and stack results as a column vector.\n",
    "\n",
    "    This is useful for the manual NeuralNet implementation,\n",
    "    which usually expects a single sample as input to predict().\n",
    "    \"\"\"\n",
    "    return np.array([model.predict(x) for x in X]).reshape(-1, 1)\n",
    "\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Safe MAPE implementation (ignores zero targets).\n",
    "\n",
    "    MAPE = Mean Absolute Percentage Error (in %).\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true).ravel()\n",
    "    y_pred = np.asarray(y_pred).ravel()\n",
    "    mask = y_true != 0\n",
    "    if not np.any(mask):\n",
    "        return np.nan\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f70f0d",
   "metadata": {},
   "source": [
    "# Execution of BP from scratch (One manual experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6290d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_experiment(hidden_layers, epochs, lr, momentum,\n",
    "                   activation='tanh', val_split=0.2):\n",
    "    \"\"\"\n",
    "    Runs one BP experiment on the Bike Sharing data using the custom NeuralNet.\n",
    "\n",
    "    Outside the NeuralNet class:\n",
    "      - We split the dataset into:\n",
    "            80% -> train+validation (X_trainval_np, y_trainval_scaled)\n",
    "            20% -> test           (X_test_np, y_test_scaled)\n",
    "\n",
    "    Inside the NeuralNet class:\n",
    "      - val_split controls the percentage of validation inside the 80%.\n",
    "      - The class automatically shuffles and splits the 80% into:\n",
    "            (1 - val_split) -> internal training\n",
    "            val_split       -> internal validation\n",
    "\n",
    "    This function:\n",
    "      - trains the network on the 80% (with internal train/val),\n",
    "      - computes predictions on the 80% and on the 20% test,\n",
    "      - returns metrics in the original target scale (cnt_log).\n",
    "    \"\"\"\n",
    "\n",
    "    # Build full layer structure: [input, hidden..., output]\n",
    "    layers = [n_features] + hidden_layers + [1]\n",
    "\n",
    "    # Initialize and train network\n",
    "    net = NeuralNet(\n",
    "        n=layers,\n",
    "        fact=activation,\n",
    "        eta=lr,\n",
    "        alpha=momentum,\n",
    "        epochs=epochs,\n",
    "        val_split=val_split\n",
    "    )\n",
    "\n",
    "    # Train on the 80% (network internally splits into train/val)\n",
    "    net.fit(X_trainval_np, y_trainval_scaled)\n",
    "\n",
    "    # Error evolution per epoch (from NeuralNet)\n",
    "    train_err, val_err = net.loss_epochs()\n",
    "\n",
    "    # --- Predictions in scaled space ---\n",
    "    y_trainval_pred_scaled = predict_batch(net, X_trainval_np)\n",
    "    y_test_pred_scaled     = predict_batch(net, X_test_np)\n",
    "\n",
    "    # --- Back to original target scale (cnt_log) ---\n",
    "    y_trainval_pred = y_scaler.inverse_transform(y_trainval_pred_scaled).ravel()\n",
    "    y_test_pred     = y_scaler.inverse_transform(y_test_pred_scaled).ravel()\n",
    "\n",
    "    # --- Metrics (in original cnt_log scale) ---\n",
    "    trainval_mse  = mean_squared_error(y_trainval, y_trainval_pred)\n",
    "    test_mse      = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "    trainval_mae  = mean_absolute_error(y_trainval, y_trainval_pred)\n",
    "    test_mae      = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "    trainval_mape = mape(y_trainval, y_trainval_pred)\n",
    "    test_mape     = mape(y_test, y_test_pred)\n",
    "\n",
    "    res = {\n",
    "        \"model\": net,\n",
    "        \"train_err\": train_err,\n",
    "        \"val_err\": val_err,\n",
    "        \"Number of layers\": len(layers),\n",
    "        \"Layer Structure\": layers,\n",
    "        \"Num epochs\": epochs,\n",
    "        \"Learning Rate\": lr,\n",
    "        \"Momentum\": momentum,\n",
    "        \"Activation function\": activation,\n",
    "\n",
    "        # Metrics on the 80% (train+val combined)\n",
    "        \"TRAINVAL_MSE\": trainval_mse,\n",
    "        \"TRAINVAL_MAE\": trainval_mae,\n",
    "        \"TRAINVAL_MAPE\": trainval_mape,\n",
    "\n",
    "        # Metrics on the 20% test set\n",
    "        \"TEST_MSE\": test_mse,\n",
    "        \"TEST_MAE\": test_mae,\n",
    "        \"TEST_MAPE\": test_mape,\n",
    "    }\n",
    "\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b853651",
   "metadata": {},
   "source": [
    "# Define list wth 4 sets of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b411068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_list = [\n",
    "\n",
    "    # --- 1: Shallow tanh ---\n",
    "    {\n",
    "        \"hidden_layers\": [20],\n",
    "        \"epochs\": 400,\n",
    "        \"lr\": 0.005,\n",
    "        \"momentum\": 0.5,\n",
    "        \"activation\": \"tanh\"\n",
    "    },\n",
    "\n",
    "    # --- 2: Deeper tanh ---\n",
    "    {\n",
    "        \"hidden_layers\": [40, 15],\n",
    "        \"epochs\": 600,\n",
    "        \"lr\": 0.005,\n",
    "        \"momentum\": 0.9,\n",
    "        \"activation\": \"tanh\"\n",
    "    },\n",
    "\n",
    "    # --- 3: Shallow sigmoid ---\n",
    "    {\n",
    "        \"hidden_layers\": [20],\n",
    "        \"epochs\": 400,\n",
    "        \"lr\": 0.005,\n",
    "        \"momentum\": 0.5,\n",
    "        \"activation\": \"sigmoid\"\n",
    "    },\n",
    "\n",
    "    # --- 4: Deeper ReLU ---\n",
    "    {\n",
    "        \"hidden_layers\": [40, 15],\n",
    "        \"epochs\": 600,\n",
    "        \"lr\": 0.005,\n",
    "        \"momentum\": 0.9,\n",
    "        \"activation\": \"relu\"\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261a79fc",
   "metadata": {},
   "source": [
    "# Run the 4 experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b0beef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================\n",
      "Running Experiment 1\n",
      "Config: {'hidden_layers': [20], 'epochs': 400, 'lr': 0.005, 'momentum': 0.5, 'activation': 'tanh'}\n",
      "====================================\n",
      "Neural network has been initialized\n",
      "Architecture (neurons per layer): [61, 20, 1]\n",
      "Activation function used: tanh\n",
      " Layer 1: w(20, 61), theta(20, 1)\n",
      " Layer 2: w(1, 20), theta(1, 1)\n",
      "Epoch 0: Train MSE=0.115037 | Val MSE=0.066814\n",
      "Epoch 100: Train MSE=0.003727 | Val MSE=0.037243\n",
      "Epoch 200: Train MSE=0.001753 | Val MSE=0.037746\n",
      "Epoch 300: Train MSE=0.000959 | Val MSE=0.040257\n",
      "\n",
      "====================================\n",
      "Running Experiment 2\n",
      "Config: {'hidden_layers': [40, 15], 'epochs': 600, 'lr': 0.005, 'momentum': 0.9, 'activation': 'tanh'}\n",
      "====================================\n",
      "Neural network has been initialized\n",
      "Architecture (neurons per layer): [61, 40, 15, 1]\n",
      "Activation function used: tanh\n",
      " Layer 1: w(40, 61), theta(40, 1)\n",
      " Layer 2: w(15, 40), theta(15, 1)\n",
      " Layer 3: w(1, 15), theta(1, 1)\n",
      "Epoch 0: Train MSE=0.108875 | Val MSE=0.062370\n",
      "Epoch 100: Train MSE=0.000234 | Val MSE=0.023093\n",
      "Epoch 200: Train MSE=0.000105 | Val MSE=0.021677\n",
      "Epoch 300: Train MSE=0.000057 | Val MSE=0.022537\n",
      "Epoch 400: Train MSE=0.000044 | Val MSE=0.022125\n",
      "Epoch 500: Train MSE=0.000036 | Val MSE=0.021757\n",
      "\n",
      "====================================\n",
      "Running Experiment 3\n",
      "Config: {'hidden_layers': [20], 'epochs': 400, 'lr': 0.005, 'momentum': 0.5, 'activation': 'sigmoid'}\n",
      "====================================\n",
      "Neural network has been initialized\n",
      "Architecture (neurons per layer): [61, 20, 1]\n",
      "Activation function used: sigmoid\n",
      " Layer 1: w(20, 61), theta(20, 1)\n",
      " Layer 2: w(1, 20), theta(1, 1)\n",
      "Epoch 0: Train MSE=0.302176 | Val MSE=0.108504\n",
      "Epoch 100: Train MSE=0.010146 | Val MSE=0.013758\n",
      "Epoch 200: Train MSE=0.006813 | Val MSE=0.013838\n",
      "Epoch 300: Train MSE=0.004538 | Val MSE=0.015035\n",
      "\n",
      "====================================\n",
      "Running Experiment 4\n",
      "Config: {'hidden_layers': [40, 15], 'epochs': 600, 'lr': 0.005, 'momentum': 0.9, 'activation': 'relu'}\n",
      "====================================\n",
      "Neural network has been initialized\n",
      "Architecture (neurons per layer): [61, 40, 15, 1]\n",
      "Activation function used: relu\n",
      " Layer 1: w(40, 61), theta(40, 1)\n",
      " Layer 2: w(15, 40), theta(15, 1)\n",
      " Layer 3: w(1, 15), theta(1, 1)\n",
      "Epoch 0: Train MSE=0.161680 | Val MSE=0.086983\n",
      "Epoch 100: Train MSE=0.000945 | Val MSE=0.026008\n",
      "Epoch 200: Train MSE=0.000347 | Val MSE=0.024879\n",
      "Epoch 300: Train MSE=0.000182 | Val MSE=0.027083\n",
      "Epoch 400: Train MSE=0.000239 | Val MSE=0.026835\n",
      "Epoch 500: Train MSE=0.000153 | Val MSE=0.026948\n",
      "\n",
      "=== Summary of all manual BP experiments ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Number of layers</th>\n",
       "      <th>Layer Structure</th>\n",
       "      <th>Num epochs</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Momentum</th>\n",
       "      <th>Activation function</th>\n",
       "      <th>TRAINVAL_MSE</th>\n",
       "      <th>TRAINVAL_MAE</th>\n",
       "      <th>TRAINVAL_MAPE</th>\n",
       "      <th>TEST_MSE</th>\n",
       "      <th>TEST_MAE</th>\n",
       "      <th>TEST_MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[61, 20, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.5</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.037926</td>\n",
       "      <td>0.105800</td>\n",
       "      <td>3.198342</td>\n",
       "      <td>0.185323</td>\n",
       "      <td>0.321170</td>\n",
       "      <td>11.125083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>[61, 40, 15, 1]</td>\n",
       "      <td>600</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.9</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.018124</td>\n",
       "      <td>0.053801</td>\n",
       "      <td>1.837297</td>\n",
       "      <td>0.082356</td>\n",
       "      <td>0.151568</td>\n",
       "      <td>6.931774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[61, 20, 1]</td>\n",
       "      <td>400</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.5</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.021249</td>\n",
       "      <td>0.089967</td>\n",
       "      <td>3.013636</td>\n",
       "      <td>0.070456</td>\n",
       "      <td>0.153016</td>\n",
       "      <td>6.992538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[61, 40, 15, 1]</td>\n",
       "      <td>600</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.9</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.021993</td>\n",
       "      <td>0.066506</td>\n",
       "      <td>2.387277</td>\n",
       "      <td>0.102897</td>\n",
       "      <td>0.192352</td>\n",
       "      <td>8.721330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Experiment  Number of layers  Layer Structure  Num epochs  Learning Rate  \\\n",
       "0           1                 3      [61, 20, 1]         400          0.005   \n",
       "1           2                 4  [61, 40, 15, 1]         600          0.005   \n",
       "2           3                 3      [61, 20, 1]         400          0.005   \n",
       "3           4                 4  [61, 40, 15, 1]         600          0.005   \n",
       "\n",
       "   Momentum Activation function  TRAINVAL_MSE  TRAINVAL_MAE  TRAINVAL_MAPE  \\\n",
       "0       0.5                tanh      0.037926      0.105800       3.198342   \n",
       "1       0.9                tanh      0.018124      0.053801       1.837297   \n",
       "2       0.5             sigmoid      0.021249      0.089967       3.013636   \n",
       "3       0.9                relu      0.021993      0.066506       2.387277   \n",
       "\n",
       "   TEST_MSE  TEST_MAE  TEST_MAPE  \n",
       "0  0.185323  0.321170  11.125083  \n",
       "1  0.082356  0.151568   6.931774  \n",
       "2  0.070456  0.153016   6.992538  \n",
       "3  0.102897  0.192352   8.721330  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for i, cfg in enumerate(hyperparams_list, start=1):\n",
    "    print(\"\\n====================================\")\n",
    "    print(f\"Running Experiment {i}\")\n",
    "    print(\"Config:\", cfg)\n",
    "    print(\"====================================\")\n",
    "\n",
    "    res = run_experiment(\n",
    "        hidden_layers=cfg[\"hidden_layers\"],\n",
    "        epochs=cfg[\"epochs\"],\n",
    "        lr=cfg[\"lr\"],\n",
    "        momentum=cfg[\"momentum\"],\n",
    "        activation=cfg[\"activation\"],\n",
    "        val_split=0.2      # keep same val_split for all\n",
    "    )\n",
    "\n",
    "    res[\"Experiment\"] = i\n",
    "    all_results.append(res)\n",
    "\n",
    "# Build a DataFrame with the most important fields\n",
    "cols = [\n",
    "    \"Experiment\",\n",
    "    \"Number of layers\",\n",
    "    \"Layer Structure\",\n",
    "    \"Num epochs\",\n",
    "    \"Learning Rate\",\n",
    "    \"Momentum\",\n",
    "    \"Activation function\",\n",
    "    \"TRAINVAL_MSE\", \"TRAINVAL_MAE\", \"TRAINVAL_MAPE\",\n",
    "    \"TEST_MSE\", \"TEST_MAE\", \"TEST_MAPE\",\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame(all_results)[cols]\n",
    "\n",
    "print(\"\\n=== Summary of all manual BP experiments ===\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a982570",
   "metadata": {},
   "source": [
    "# Execution of MLR (scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd770af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Linear Regression (scikit-learn) initialized.\n",
      "fit_intercept: True\n",
      "\n",
      "=== Multiple Linear Regression (scikit-learn) ===\n",
      "TRAIN+VAL -> MSE: 0.2025, MAE: 0.3162, MAPE: 10.62%\n",
      "TEST      -> MSE: 0.2202, MAE: 0.3202, MAPE: 12.33%\n"
     ]
    }
   ],
   "source": [
    "# We train MLR on the same scaled data as the neural networks.\n",
    "mlr = MultipleLinearRegressionSK(fit_intercept=True)\n",
    "\n",
    "mlr.fit(X_trainval_np, y_trainval_scaled)\n",
    "\n",
    "# Predictions in scaled space\n",
    "y_trainval_pred_mlr_scaled = mlr.predict(X_trainval_np).reshape(-1, 1)\n",
    "y_test_pred_mlr_scaled     = mlr.predict(X_test_np).reshape(-1, 1)\n",
    "\n",
    "# Back to original target scale (cnt_log)\n",
    "y_trainval_pred_mlr = y_scaler.inverse_transform(y_trainval_pred_mlr_scaled).ravel()\n",
    "y_test_pred_mlr     = y_scaler.inverse_transform(y_test_pred_mlr_scaled).ravel()\n",
    "\n",
    "# Metrics (in original cnt_log scale)\n",
    "trainval_mse_mlr  = mean_squared_error(y_trainval, y_trainval_pred_mlr)\n",
    "test_mse_mlr      = mean_squared_error(y_test, y_test_pred_mlr)\n",
    "\n",
    "trainval_mae_mlr  = mean_absolute_error(y_trainval, y_trainval_pred_mlr)\n",
    "test_mae_mlr      = mean_absolute_error(y_test, y_test_pred_mlr)\n",
    "\n",
    "trainval_mape_mlr = mape(y_trainval, y_trainval_pred_mlr)\n",
    "test_mape_mlr     = mape(y_test, y_test_pred_mlr)\n",
    "\n",
    "print(\"\\n=== Multiple Linear Regression (scikit-learn) ===\")\n",
    "print(f\"TRAIN+VAL -> MSE: {trainval_mse_mlr:.4f}, MAE: {trainval_mae_mlr:.4f}, MAPE: {trainval_mape_mlr:.2f}%\")\n",
    "print(f\"TEST      -> MSE: {test_mse_mlr:.4f}, MAE: {test_mae_mlr:.4f}, MAPE: {test_mape_mlr:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85df2d9",
   "metadata": {},
   "source": [
    "# Execution of PyTorch NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f291a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using configuration from manual BP experiment: 2 -> {'hidden_layers': [40, 15], 'epochs': 600, 'lr': 0.005, 'momentum': 0.9, 'activation': 'tanh'}\n",
      "Neural network (PyTorch) initialized.\n",
      "Layers: [61, 40, 15, 1]\n",
      "Activation: tanh\n",
      "Epoch 0: Train MSE=1.001849 | Val MSE=0.961159\n",
      "Epoch 100: Train MSE=0.095751 | Val MSE=0.080517\n",
      "Epoch 200: Train MSE=0.079744 | Val MSE=0.071580\n",
      "Epoch 300: Train MSE=0.068534 | Val MSE=0.066015\n",
      "Epoch 400: Train MSE=0.058300 | Val MSE=0.060804\n",
      "Epoch 500: Train MSE=0.048738 | Val MSE=0.055672\n",
      "\n",
      "=== PyTorch Neural Network (chosen config) ===\n",
      "TRAIN+VAL -> MSE: 0.0838, MAE: 0.1894, MAPE: 7.07%\n",
      "TEST      -> MSE: 0.1267, MAE: 0.2167, MAPE: 9.39%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Here you can choose manually which experiment configuration\n",
    "# from hyperparams_list you want to replicate with PyTorch.\n",
    "#\n",
    "# Example: choose experiment 2 (index 1) or any other.\n",
    "\n",
    "chosen_experiment_index = 1  # 0-based index -> 0,1,2,3  (here: experiment 2)\n",
    "chosen_cfg = hyperparams_list[chosen_experiment_index]\n",
    "\n",
    "print(\"\\nUsing configuration from manual BP experiment:\",\n",
    "      chosen_experiment_index + 1, \"->\", chosen_cfg)\n",
    "\n",
    "hidden_layers_torch = chosen_cfg[\"hidden_layers\"]\n",
    "layers_torch = [n_features] + hidden_layers_torch + [1]\n",
    "\n",
    "net_torch = NeuralNetTorch(\n",
    "    n=layers_torch,\n",
    "    fact=chosen_cfg[\"activation\"],   # same activation\n",
    "    eta=chosen_cfg[\"lr\"],            # same learning rate\n",
    "    alpha=chosen_cfg[\"momentum\"],    # same momentum\n",
    "    epochs=chosen_cfg[\"epochs\"],     # same number of epochs\n",
    "    val_split=0.2                    # same validation split as manual net\n",
    ")\n",
    "\n",
    "# Train with scaled data\n",
    "net_torch.fit(X_trainval_np, y_trainval_scaled)\n",
    "\n",
    "# Loss history for later plots\n",
    "train_err_torch, val_err_torch = net_torch.loss_epochs()\n",
    "\n",
    "# Predictions in scaled space\n",
    "y_trainval_pred_torch_scaled = net_torch.predict(X_trainval_np).reshape(-1, 1)\n",
    "y_test_pred_torch_scaled     = net_torch.predict(X_test_np).reshape(-1, 1)\n",
    "\n",
    "# Back to original target scale (cnt_log)\n",
    "y_trainval_pred_torch = y_scaler.inverse_transform(y_trainval_pred_torch_scaled).ravel()\n",
    "y_test_pred_torch     = y_scaler.inverse_transform(y_test_pred_torch_scaled).ravel()\n",
    "\n",
    "# Metrics (in original cnt_log scale)\n",
    "trainval_mse_torch  = mean_squared_error(y_trainval, y_trainval_pred_torch)\n",
    "test_mse_torch      = mean_squared_error(y_test, y_test_pred_torch)\n",
    "\n",
    "trainval_mae_torch  = mean_absolute_error(y_trainval, y_trainval_pred_torch)\n",
    "test_mae_torch      = mean_absolute_error(y_test, y_test_pred_torch)\n",
    "\n",
    "trainval_mape_torch = mape(y_trainval, y_trainval_pred_torch)\n",
    "test_mape_torch     = mape(y_test, y_test_pred_torch)\n",
    "\n",
    "print(\"\\n=== PyTorch Neural Network (chosen config) ===\")\n",
    "print(f\"TRAIN+VAL -> MSE: {trainval_mse_torch:.4f}, MAE: {trainval_mae_torch:.4f}, MAPE: {trainval_mape_torch:.2f}%\")\n",
    "print(f\"TEST      -> MSE: {test_mse_torch:.4f}, MAE: {test_mae_torch:.4f}, MAPE: {test_mape_torch:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
